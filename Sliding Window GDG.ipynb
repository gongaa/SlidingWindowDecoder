{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b3919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.dev1701377008\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import stim\n",
    "print(stim.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from ldpc import bp_decoder, bposd_decoder\n",
    "import time\n",
    "from src.utils import rank\n",
    "from src.codes_q import create_bivariate_bicycle_codes, create_circulant_matrix\n",
    "from src.build_circuit import build_circuit, dem_to_check_matrices\n",
    "from src import bpgdg_decoder\n",
    "\n",
    "hard_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a478e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_time = []\n",
    "def sliding_window_decoder(N, p=0.003, num_repeat=12, num_shots=10000, max_iter=200, W=3, F=1, z_basis=True, \n",
    "                           noisy_prior=None, method=1, plot=False, low_error_mode=False,\n",
    "                           max_step=25, max_iter_per_step=6, max_tree_depth=3, max_side_depth=10, max_side_branch_step=10,\n",
    "                           last_win_gdg_factor=1.0, last_win_bp_factor=1.0):\n",
    "    \n",
    "    if N == 72:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(6, 6, [3], [1,2], [1,2], [3]) # 72\n",
    "    elif N == 90:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(15, 3, [9], [1,2], [2,7], [0]) # 90\n",
    "    elif N == 108:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(9, 6, [3], [1,2], [1,2], [3]) # 108\n",
    "    elif N == 144:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(12, 6, [3], [1,2], [1,2], [3]) # 144\n",
    "    elif N == 288:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(12, 12, [3], [2,7], [1,2], [3]) # 288\n",
    "    elif N == 360:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(30, 6, [9], [1,2], [25,26], [3]) # 360\n",
    "    elif N == 756:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(21,18, [3], [10,17], [3,19], [5]) # 756\n",
    "    else:\n",
    "        print(\"unsupported N\")\n",
    "        return\n",
    "\n",
    "    circuit = build_circuit(code, A_list, B_list, p, num_repeat, z_basis=z_basis)\n",
    "    dem = circuit.detector_error_model()\n",
    "    chk, obs, priors, col_dict = dem_to_check_matrices(dem, return_col_dict=True)\n",
    "    num_row, num_col = chk.shape\n",
    "    n = code.N\n",
    "    n_half = n//2\n",
    "\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    i = 0\n",
    "    while i < num_row:\n",
    "        lower_bounds.append(i)\n",
    "        upper_bounds.append(i+n_half)\n",
    "        if i+n > num_row:\n",
    "            break\n",
    "        lower_bounds.append(i)\n",
    "        upper_bounds.append(i+n)\n",
    "        i += n_half\n",
    "\n",
    "    region_dict = {}\n",
    "    for i, (l,u) in enumerate(zip(lower_bounds, upper_bounds)):\n",
    "        region_dict[(l,u)] = i\n",
    "\n",
    "    region_cols = [[] for _ in range(len(region_dict))]\n",
    "\n",
    "    for i in range(num_col):\n",
    "        nnz_col = np.nonzero(chk[:,i])[0]\n",
    "        l = nnz_col.min() // n_half * n_half\n",
    "        u = (nnz_col.max() // n_half + 1) * n_half\n",
    "        region_cols[region_dict[(l,u)]].append(i)  \n",
    "\n",
    "    chk = np.concatenate([chk[:,col].toarray() for col in region_cols], axis=1)\n",
    "    obs = np.concatenate([obs[:,col].toarray() for col in region_cols], axis=1)\n",
    "    priors = np.concatenate([priors[col] for col in region_cols])\n",
    "\n",
    "    anchors = []\n",
    "    j = 0\n",
    "    for i in range(num_col):\n",
    "        nnz_col = np.nonzero(chk[:,i])[0]\n",
    "        if (nnz_col.min() >= j):\n",
    "            anchors.append((j, i))\n",
    "            j += n_half\n",
    "    anchors.append((num_row, num_col))\n",
    "    \n",
    "    if noisy_prior is None and method != 0:\n",
    "        b = anchors[W]\n",
    "        c = anchors[W-1]\n",
    "        if method == 1:\n",
    "            c = (c[0], c[1]+n_half*3) # try also this for x basis\n",
    "        noisy_prior = np.sum(chk[c[0]:b[0],c[1]:b[1]] * priors[c[1]:b[1]], axis=1)\n",
    "        print(\"prior for noisy syndrome\", noisy_prior[0])\n",
    "\n",
    "    if method != 0:\n",
    "        noisy_syndrome_priors = np.ones(n_half) * noisy_prior\n",
    "    \n",
    "    num_win = math.ceil((len(anchors)-W+F-1) / F)\n",
    "    chk_submats = []\n",
    "    prior_subvecs = []\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(num_win, 1)\n",
    "    top_left = 0\n",
    "\n",
    "    for i in range(num_win):\n",
    "        a = anchors[top_left]\n",
    "        bottom_right = min(top_left + W, len(anchors)-1)\n",
    "        b = anchors[bottom_right]\n",
    "\n",
    "        if i != num_win-1 and method != 0: # not the last round\n",
    "            c = anchors[top_left + W - 1]\n",
    "            if method == 1:\n",
    "                c = (c[0], c[1]+n_half*3) # try also this for x basis\n",
    "            noisy_syndrome = np.zeros((n_half*W,n_half))\n",
    "            noisy_syndrome[-n_half:,:] = np.eye(n_half)# * noisy_syndrome_prior\n",
    "            mat = chk[a[0]:b[0],a[1]:c[1]]\n",
    "            mat = np.hstack((mat, noisy_syndrome))\n",
    "            prior = priors[a[1]:c[1]]\n",
    "            prior = np.concatenate((prior, noisy_syndrome_priors))\n",
    "        else: # method==0 or last round\n",
    "            mat = chk[a[0]:b[0],a[1]:b[1]]\n",
    "            prior = priors[a[1]:b[1]]\n",
    "        chk_submats.append(mat)\n",
    "        prior_subvecs.append(prior)\n",
    "        if plot:\n",
    "            ax[i].imshow(mat, cmap=\"gist_yarg\")\n",
    "        top_left += F\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    dem_sampler: stim.CompiledDemSampler = dem.compile_sampler()\n",
    "    det_data, obs_data, err_data = dem_sampler.sample(shots=num_shots, return_errors=False, bit_packed=False)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Stim: noise sampling for {num_shots} shots, elapsed time:\", end_time-start_time)\n",
    "\n",
    "\n",
    "    total_e_hat = np.zeros((num_shots,num_col))\n",
    "    new_det_data = det_data.copy()\n",
    "    start_time = time.perf_counter()\n",
    "    top_left = 0\n",
    "    i = 0\n",
    "    osd = False\n",
    "    while i < num_win:\n",
    "        mat = chk_submats[i]\n",
    "        prior = prior_subvecs[i]\n",
    "        a = anchors[top_left]\n",
    "        bottom_right = min(top_left + W, len(anchors)-1)\n",
    "        b = anchors[bottom_right]\n",
    "        c = anchors[top_left+F] # commit region bottom right\n",
    "\n",
    "        if i==num_win-1 and osd:\n",
    "            bpd = bposd_decoder(\n",
    "                mat, # the parity check matrix\n",
    "                error_rate=p, # does not matter because channel_probs is assigned\n",
    "                channel_probs=prior, # assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "                max_iter=200, # the maximum number of iterations for BP)\n",
    "                bp_method=\"minimum_sum_log\",\n",
    "                ms_scaling_factor=1.0,\n",
    "                input_vector_type=\"syndrome\", # \"received_vector\"\n",
    "                osd_method=\"osd_cs\",\n",
    "                osd_order=10,\n",
    "            )\n",
    "        else:\n",
    "            bpgdg = bpgdg_decoder(\n",
    "                mat,\n",
    "                channel_probs=prior,\n",
    "                max_iter=max_iter,\n",
    "                ms_scaling_factor=last_win_bp_factor if (i==num_win-1) else 1.0,\n",
    "                max_iter_per_step=max_iter_per_step,\n",
    "                max_step=max_step,\n",
    "                max_tree_depth=max_tree_depth,\n",
    "                max_side_depth=max_side_depth,\n",
    "                max_tree_branch_step=max_side_branch_step,\n",
    "                max_side_branch_step=max_side_branch_step,\n",
    "                multi_thread=True, # change to False if you don't have enough logical cores\n",
    "                low_error_mode=low_error_mode,\n",
    "                gdg_factor=last_win_gdg_factor if (i==num_win-1) else 1.0,\n",
    "            )\n",
    "        num_flag_err = 0\n",
    "        # if i==num_win - 1: # after gathering hard sample, uncomment these two lines\n",
    "        #     return mat, prior # to get mat and prior for the last window\n",
    "        detector_win = new_det_data[:,a[0]:b[0]]\n",
    "        llr_prior = np.log((1.0-prior)/prior)\n",
    "        sum_wt = 0\n",
    "        for j in range(num_shots):\n",
    "            if i==num_win-1 and osd:\n",
    "                e_hat = bpd.decode(detector_win[j])\n",
    "                is_flagged = ((mat @ e_hat + detector_win[j]) % 2).any()\n",
    "            else:\n",
    "                # e_hat_osd = bpd.decode(detector_win[j])\n",
    "                # decoding_start_time = time.perf_counter()\n",
    "                e_hat = bpgdg.decode(detector_win[j])\n",
    "\n",
    "                # pm_osd = llr_prior[e_hat_osd.astype(bool)].sum()\n",
    "                # pm_gdg = llr_prior[e_hat.astype(bool)].sum()\n",
    "                # if pm_osd != pm_gdg:\n",
    "                #     print(f\"osd pm {pm_osd}, gdg pm {pm_gdg}\")\n",
    "                # decoding_end_time = time.perf_counter()\n",
    "                is_flagged = 1 - bpgdg.converge\n",
    "                # if is_flagged: decoding_time.append(decoding_end_time-decoding_start_time)\n",
    "                \n",
    "                # if is_flagged and i==num_win-1:\n",
    "                #     hard_samples.append(detector_win[j])\n",
    "            sum_wt += e_hat.sum()                \n",
    "            num_flag_err += is_flagged\n",
    "            if i == num_win-1: # last window\n",
    "                total_e_hat[j][a[1]:b[1]] = e_hat\n",
    "            else:\n",
    "                total_e_hat[j][a[1]:c[1]] = e_hat[:c[1]-a[1]]\n",
    "          \n",
    "        print(f\"Window {i}, average weight {sum_wt/num_shots}\")\n",
    "        print(f\"Window {i}, flagged Errors: {num_flag_err}/{num_shots}\")\n",
    "\n",
    "        if i!=num_win - 1:\n",
    "            new_det_data = (det_data + total_e_hat @ chk.T) % 2\n",
    "            top_left += F\n",
    "        else:\n",
    "            end_time = time.perf_counter()\n",
    "            print(\"Elapsed time:\", end_time-start_time)    \n",
    "            print(\"last round osd\", osd)\n",
    "            flagged_err = ((det_data + total_e_hat @ chk.T) % 2).any(axis=1)\n",
    "            num_flagged_err = flagged_err.astype(int).sum()\n",
    "            print(f\"Overall Flagged Errors: {num_flagged_err}/{num_shots}\")\n",
    "            logical_err = ((obs_data + total_e_hat @ obs.T) % 2).any(axis=1)\n",
    "            num_err = np.logical_or(flagged_err, logical_err).astype(int).sum()\n",
    "            # print(f\"Pure logical equation fail: {logical_err.astype(int).sum()}/{num_shots}\")\n",
    "            print(f\"Logical Errors: {num_err}/{num_shots}\")\n",
    "            p_l = num_err / num_shots\n",
    "            p_l_per_round = 1-(1-p_l) ** (1/num_repeat)\n",
    "            print(\"logical error per round:\", p_l_per_round)\n",
    "            # return # uncomment if you don't want to run OSD on the last window\n",
    "        \n",
    "        if i==num_win - 1 and osd:\n",
    "            break\n",
    "            \n",
    "        if i==num_win - 1 and (not osd):\n",
    "            i -= 1\n",
    "            osd = True\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433676ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for noisy syndrome 0.04572241379526658\n",
      "Stim: noise sampling for 5000 shots, elapsed time: 0.013337283999135252\n",
      "Window 0, average weight 13.0938\n",
      "Window 0, flagged Errors: 2/5000\n",
      "Window 1, average weight 13.39\n",
      "Window 1, flagged Errors: 9/5000\n",
      "Window 2, average weight 13.424\n",
      "Window 2, flagged Errors: 6/5000\n",
      "Window 3, average weight 13.4208\n",
      "Window 3, flagged Errors: 10/5000\n",
      "Window 4, average weight 13.4842\n",
      "Window 4, flagged Errors: 14/5000\n",
      "Window 5, average weight 13.5044\n",
      "Window 5, flagged Errors: 7/5000\n",
      "Window 6, average weight 13.605\n",
      "Window 6, flagged Errors: 16/5000\n",
      "Window 7, average weight 13.645\n",
      "Window 7, flagged Errors: 13/5000\n",
      "Window 8, average weight 13.693\n",
      "Window 8, flagged Errors: 21/5000\n",
      "Window 9, average weight 13.7218\n",
      "Window 9, flagged Errors: 22/5000\n",
      "Window 10, average weight 10.3868\n",
      "Window 10, flagged Errors: 178/5000\n",
      "Elapsed time: 68.67507666399979\n",
      "last round osd False\n",
      "Overall Flagged Errors: 180/5000\n",
      "Logical Errors: 400/5000\n",
      "logical error per round: 0.006924382628299419\n",
      "Window 10, average weight 10.0462\n",
      "Window 10, flagged Errors: 76/5000\n",
      "Elapsed time: 81.04848947700157\n",
      "last round osd True\n",
      "Overall Flagged Errors: 78/5000\n",
      "Logical Errors: 398/5000\n",
      "logical error per round: 0.006888408795805878\n"
     ]
    }
   ],
   "source": [
    "# Please use `low_error_mode=True` when p<=0.002 for (3,1)-window decoding of all the codes.\n",
    "\n",
    "# sliding_window_decoder(N=72, p=0.005, num_repeat=6, W=3, F=1, num_shots=5000, max_iter=8, method=1, z_basis=True)\n",
    "\n",
    "# sliding_window_decoder(N=90, p=0.005, num_repeat=10, W=3, F=1, num_shots=5000, max_iter=8, method=1, z_basis=True)\n",
    "\n",
    "# sliding_window_decoder(N=108, p=0.005, num_repeat=10, W=3, F=1, num_shots=5000, max_iter=8, method=1, z_basis=True)\n",
    "\n",
    "sliding_window_decoder(N=144, p=0.005, num_repeat=12, W=3, F=1, num_shots=5000, max_iter=8, method=1, z_basis=True,\n",
    "                       low_error_mode=False)\n",
    "\n",
    "# sliding_window_decoder(N=288, p=0.005, num_repeat=18, W=3, F=1, num_shots=10000, max_iter=16, method=1, z_basis=True,\n",
    "#                        max_step=40, max_tree_depth=4, max_side_depth=20, max_side_branch_step=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83f0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for noisy syndrome 0.036622121785736664\n",
      "Stim: noise sampling for 50000 shots, elapsed time: 0.38410777412354946\n",
      "Window 0, average weight 28.21366\n",
      "Window 0, flagged Errors: 0/50000\n",
      "Window 1, average weight 28.5786\n",
      "Window 1, flagged Errors: 3/50000\n",
      "Window 2, average weight 28.56374\n",
      "Window 2, flagged Errors: 4/50000\n",
      "Window 3, average weight 28.57962\n",
      "Window 3, flagged Errors: 4/50000\n",
      "Window 4, average weight 28.56298\n",
      "Window 4, flagged Errors: 6/50000\n",
      "Window 5, average weight 28.57642\n",
      "Window 5, flagged Errors: 9/50000\n",
      "Window 6, average weight 28.60648\n",
      "Window 6, flagged Errors: 11/50000\n",
      "Window 7, average weight 28.64158\n",
      "Window 7, flagged Errors: 14/50000\n",
      "Window 8, average weight 28.6721\n",
      "Window 8, flagged Errors: 9/50000\n",
      "Window 9, average weight 28.64092\n",
      "Window 9, flagged Errors: 6/50000\n",
      "Window 10, average weight 28.67692\n",
      "Window 10, flagged Errors: 8/50000\n",
      "Window 11, average weight 28.65528\n",
      "Window 11, flagged Errors: 7/50000\n",
      "Window 12, average weight 28.65516\n",
      "Window 12, flagged Errors: 13/50000\n",
      "Window 13, average weight 28.63356\n",
      "Window 13, flagged Errors: 11/50000\n",
      "Window 14, average weight 28.6272\n",
      "Window 14, flagged Errors: 12/50000\n",
      "Window 15, average weight 22.3923\n",
      "Window 15, flagged Errors: 120/50000\n",
      "Elapsed time: 6993.641995867714\n",
      "last round osd False\n",
      "Overall Flagged Errors: 120/50000\n",
      "Logical Errors: 128/50000\n",
      "logical error per round: 0.00014239443890295966\n",
      "Window 15, average weight 22.5044\n",
      "Window 15, flagged Errors: 53/50000\n",
      "Elapsed time: 7605.953879963607\n",
      "last round osd True\n",
      "Overall Flagged Errors: 53/50000\n",
      "Logical Errors: 123/50000\n",
      "logical error per round: 0.0001368256813728541\n"
     ]
    }
   ],
   "source": [
    "# (4,1)-window decoding of N=288\n",
    "# showing logical error rate per round `LER_per_r` at physical error rate `p`\n",
    "# LER_per_r = 1 - (1 - numError/numWords) ** (1/num_repeat) ~ (numError/numWords)/num_repeat\n",
    "# when counting numErrors, GDG is used on every window\n",
    "\n",
    "# p     LER_per_r   numWords numErrors numFlagged\n",
    "# 0.005 0.002       5000     178       165\n",
    "# 0.004 1.42e-4     50000    128       120\n",
    "# 0.003 8.38e-6     550000   83        74\n",
    "\n",
    "# sliding_window_decoder(N=288, p=0.005, num_repeat=18, W=4, F=1, num_shots=50000, max_iter=16, method=1, z_basis=True,\n",
    "#                        max_step=60, max_tree_depth=4, max_side_depth=20, max_side_branch_step=40)\n",
    "\n",
    "sliding_window_decoder(N=288, p=0.004, num_repeat=18, W=4, F=1, num_shots=50000, max_iter=16, method=1, z_basis=True,\n",
    "                       max_step=60, max_tree_depth=4, max_side_depth=20, max_side_branch_step=40, low_error_mode=True)\n",
    "\n",
    "# sliding_window_decoder(N=288, p=0.003, num_repeat=18, W=4, F=1, num_shots=50000, max_iter=16, method=1, z_basis=True,\n",
    "#                        max_step=60, max_tree_depth=4, max_side_depth=20, max_side_branch_step=40, low_error_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a942ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for noisy syndrome 0.036622121785736664\n",
      "Stim: noise sampling for 100000 shots, elapsed time: 0.1912261676043272\n",
      "Window 0, average weight 17.63464\n",
      "Window 0, flagged Errors: 17/100000\n",
      "Window 1, average weight 17.85131\n",
      "Window 1, flagged Errors: 45/100000\n",
      "Window 2, average weight 17.84256\n",
      "Window 2, flagged Errors: 52/100000\n",
      "Window 3, average weight 17.82215\n",
      "Window 3, flagged Errors: 84/100000\n",
      "Window 4, average weight 14.67987\n",
      "Window 4, flagged Errors: 159/100000\n",
      "Elapsed time: 1414.118375390768\n",
      "last round osd False\n",
      "Overall Flagged Errors: 175/100000\n",
      "Logical Errors: 719/100000\n",
      "logical error per round: 0.0006011502884101239\n",
      "Window 4, average weight 14.83584\n",
      "Window 4, flagged Errors: 128/100000\n",
      "Elapsed time: 1928.752714432776\n",
      "last round osd True\n",
      "Overall Flagged Errors: 144/100000\n",
      "Logical Errors: 817/100000\n",
      "logical error per round: 0.0006833961576264702\n"
     ]
    }
   ],
   "source": [
    "# (5,2)-window decoding of N=144\n",
    "# using GDG on every window\n",
    "# p     LER_per_r    numWords numErrors numFlagged\n",
    "# 0.005 0.00318     10000    375       90\n",
    "# 0.004 0.0006      100000   719       175 \n",
    "# 0.003 6.75e-5     100000   81        12\n",
    "# 0.002 2.9e-6      200000   7         3\n",
    "\n",
    "sliding_window_decoder(N=144, p=0.004, num_repeat=12, W=5, F=2, num_shots=100000, max_iter=8, method=1, z_basis=True,\n",
    "                       max_step=40, max_tree_depth=4, max_side_depth=20, max_side_branch_step=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e76871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for noisy syndrome 0.027499817877069083\n",
      "Stim: noise sampling for 100000 shots, elapsed time: 0.0930856205523014\n",
      "Window 0, average weight 8.39342\n",
      "Window 0, flagged Errors: 2/100000\n",
      "Window 1, average weight 8.46886\n",
      "Window 1, flagged Errors: 2/100000\n",
      "Window 2, average weight 8.47453\n",
      "Window 2, flagged Errors: 4/100000\n",
      "Window 3, average weight 6.97462\n",
      "Window 3, flagged Errors: 26/100000\n",
      "Elapsed time: 428.94448618777096\n",
      "last round osd False\n",
      "Overall Flagged Errors: 28/100000\n",
      "Logical Errors: 243/100000\n",
      "logical error per round: 0.00024326613016567578\n",
      "Window 3, average weight 7.05714\n",
      "Window 3, flagged Errors: 4/100000\n",
      "Elapsed time: 529.0016630832106\n",
      "last round osd True\n",
      "Overall Flagged Errors: 6/100000\n",
      "Logical Errors: 318/100000\n",
      "logical error per round: 0.00031845597660506986\n"
     ]
    }
   ],
   "source": [
    "sliding_window_decoder(N=90, p=0.003, num_repeat=10, W=5, F=2, num_shots=100000, max_iter=8, method=1, z_basis=True,\n",
    "                       max_step=40, max_tree_depth=4, max_side_depth=20, max_side_branch_step=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d98fe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for noisy syndrome 0.04572241379526658\n",
      "Stim: noise sampling for 5000 shots, elapsed time: 0.004279658198356628\n",
      "Window 0, average weight 13.1234\n",
      "Window 0, flagged Errors: 1/5000\n",
      "Window 1, average weight 13.398\n",
      "Window 1, flagged Errors: 5/5000\n",
      "Window 2, average weight 9.6166\n",
      "Window 2, flagged Errors: 30/5000\n",
      "Elapsed time: 16.33069814927876\n",
      "last round osd False\n",
      "Overall Flagged Errors: 30/5000\n",
      "Logical Errors: 63/5000\n",
      "logical error per round: 0.0031649941022470207\n",
      "Window 2, average weight 9.6644\n",
      "Window 2, flagged Errors: 3/5000\n",
      "Elapsed time: 24.385304428637028\n",
      "last round osd True\n",
      "Overall Flagged Errors: 3/5000\n",
      "Logical Errors: 76/5000\n",
      "logical error per round: 0.003821854082101339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 4., 9., 8., 9., 1., 0., 0., 1.]),\n",
       " array([2.21648812, 2.32431218, 2.43213624, 2.53996029, 2.64778435,\n",
       "        2.75560841, 2.86343247, 2.97125652, 3.07908058, 3.18690464,\n",
       "        3.2947287 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sliding_window_decoder(N=144, p=0.005, num_repeat=4, W=3, F=1, num_shots=5000, max_iter=8, method=1, z_basis=True)\n",
    "plt.hist([x*1000 for x in decoding_time]) # convert s to ms\n",
    "\n",
    "# Here I only gather the runtime for samples that GDG failed to converge on.\n",
    "# Theoretically, they have the worst-case runtime.\n",
    "# One can also gather runtime for every sample, but will find a few samples running for very long.\n",
    "# This is an OS issue, and please refer to this series of blog post \n",
    "# https://shuhaowu.com/blog/2022/01-linux-rt-appdev-part1.html\n",
    "# for better latency control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb3047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior for noisy syndrome 0.04572241379526658\n",
      "Stim: noise sampling for 20000 shots, elapsed time: 0.05161724401114043\n",
      "Window 0, average weight 35.09255\n",
      "Window 0, flagged Errors: 1/20000\n",
      "Window 1, average weight 35.5825\n",
      "Window 1, flagged Errors: 5/20000\n",
      "Window 2, average weight 35.70345\n",
      "Window 2, flagged Errors: 4/20000\n",
      "Window 3, average weight 27.96595\n",
      "Window 3, flagged Errors: 129/20000\n",
      "Elapsed time: 601.918304175997\n",
      "last round osd False\n",
      "Overall Flagged Errors: 129/20000\n",
      "Logical Errors: 137/20000\n",
      "logical error per round: 0.0011449388806175076\n",
      "Window 3, average weight 27.9406\n",
      "Window 3, flagged Errors: 9/20000\n",
      "Elapsed time: 1083.1758172359987\n",
      "last round osd True\n",
      "Overall Flagged Errors: 9/20000\n",
      "Logical Errors: 85/20000\n",
      "logical error per round: 0.0007095909412510037\n"
     ]
    }
   ],
   "source": [
    "sliding_window_decoder(N=288, p=0.005, num_repeat=6, W=4, F=1, num_shots=20000, max_iter=16, method=1, z_basis=True,\n",
    "                       max_step=60, max_tree_depth=4, max_side_depth=20, max_side_branch_step=40)\n",
    "\n",
    "# Using OSD in the last window **only** can improve performance, an issue I mentioned in Appendix E.\n",
    "# The improvement is only prominent for N=288 and small num_repeat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
